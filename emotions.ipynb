{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################################################################################################\n",
    "##                                                                                                                                                       ##\n",
    "## THIS IS AN ADVANCED FUNCTION TO CREATE A DASHBOARD SIMILAR TO THE FUNCTION ABOVE, HOWEVER IT INCLUDES A MACHINE LEARNING MODEL FOR EMOTIONAL ANALYSIS ##\n",
    "##                                                                                                                                                       ##    \n",
    "###########################################################################################################################################################\n",
    "\n",
    "# #SETTING UP GO EMOTIONS\n",
    "\n",
    "# from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "# import torch\n",
    "\n",
    "# #GOEMOTIONS MODEL\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-emotion\")\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-roberta-base-emotion\")\n",
    "\n",
    "# #FUNCTION \n",
    "\n",
    "# def get_emotions(texts):\n",
    "#     inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "#     outputs = model(**inputs)\n",
    "#     predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "#     max_probs, max_indices = torch.max(predictions, dim=1)\n",
    "#     emotions = [tokenizer.convert_ids_to_tokens(index.item()) for index in max_indices]\n",
    "#     return emotions\n",
    "\n",
    "# # DASHBOARD INCLUDING TIME-SERIES FOR SENTIMENT, TRENDING WORDS AND EMOTION ANALYSIS\n",
    "\n",
    "# while True:\n",
    "#     clear_output()\n",
    "#     db_connection = mysql.connector.connect(\n",
    "#         host=\"localhost\",\n",
    "#         user=\"root\",\n",
    "#         passwd=credentials.MYSQLPASSWORD,\n",
    "#         database=\"TwitterDB\",\n",
    "#         charset = 'utf8'\n",
    "#     )\n",
    "\n",
    "#     timenow=datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "#     query = \"SELECT id_str, text, created_at, polarity FROM {} WHERE created_at >= '{}' \" \\\n",
    "#                             .format(\"ethereum\",timenow)\n",
    "#     engine = create_engine('mysql+mysqlconnector://root:credentials.MYSQLPASSWORD@localhost:3306/twitterdb')\n",
    "\n",
    "#     df = pd.read_sql(query, con=db_connection)\n",
    "#     df['created_at']=pd.to_datetime(df['created_at'])\n",
    "\n",
    "# #ADDING 'EMOTIONS' TO THE DF\n",
    "\n",
    "#     df['emotion'] = get_emotions(df['text'].tolist())\n",
    "\n",
    "# #CRETING SUBPLOTS\n",
    "#     fig = make_subplots(\n",
    "#         rows=2, cols=3,\n",
    "#         column_widths=[1, 0.4, 0.4],\n",
    "#         row_heights=[0.6, 0.4],\n",
    "#         specs=[[{\"type\": \"scatter\", \"rowspan\": 2}, {\"type\": \"scatter\"}, {\"type\": \"bar\"}],\n",
    "#             [None, {\"type\": \"bar\"}, {\"type\": \"bar\"}]])\n",
    "    \n",
    "#     result=df.groupby([pd.Grouper(key='created_at', freq='2s'),'polarity']).count().unstack(fill_value=0).stack().reset_index()\n",
    "\n",
    "#     result.loc[result['polarity'] < -0.1, 'polarity'] = -1\n",
    "#     result.loc[result['polarity'] > 0.1, 'polarity'] = 1\n",
    "#     result.loc[(-0.1 <= result['polarity']) & (result['polarity'] <= 0.1), 'polarity'] = 0\n",
    "\n",
    "#     result = result.rename(columns={\"id_str\": \"Num of 'Ethereum' mentions\".format('Ethereum'[0]), \"created_at\":\"Time in UTC\"})\n",
    "#     time_series=result[\"Time in UTC\"][result['polarity']==0].reset_index(drop=True)\n",
    "    \n",
    "#     fig.add_trace(go.Scatter(\n",
    "#         x=time_series,\n",
    "#         y=result[\"Num of '{}' mentions\".format(settings.TRACK_WORDS[0])][result['polarity']==0].reset_index(drop=True),\n",
    "#         name=\"Neutral\",\n",
    "#         line=dict(color='rgb(0,143,211)'),\n",
    "#         opacity=0.8), row=1, col=1)   \n",
    "#     fig.add_trace(go.Scatter(\n",
    "#         x=time_series,\n",
    "#         y=result[\"Num of '{}' mentions\".format(settings.TRACK_WORDS[0])][result['polarity']==-1].reset_index(drop=True),\n",
    "#         name=\"Negative\",\n",
    "#         line=dict(color='rgb(255,127,0)'),\n",
    "#         opacity=0.8), row=1, col=1)\n",
    "#     fig.add_trace(go.Scatter(\n",
    "#         x=time_series,\n",
    "#         y=result[\"Num of '{}' mentions\".format(settings.TRACK_WORDS[0])][result['polarity']==1].reset_index(drop=True),\n",
    "#         name=\"Positive\",\n",
    "#         line=dict(color='rgb(0,211,202)'),\n",
    "#         opacity=0.8), row=1, col=1)\n",
    "\n",
    "    \n",
    "#     #BAR CHART\n",
    "#     content = ' '.join(df[\"text\"])\n",
    "#     content = re.sub(r\"http\\S+\", \"\", content)\n",
    "#     content = content.replace('&amp;', 'and')\n",
    "#     content = re.sub('[^A-Za-z0-9]+', ' ', content)\n",
    "#     content = content.lower()\n",
    "\n",
    "\n",
    "#     tokenwords=word_tokenize(content)\n",
    "#     stop_words=set(stopwords.words('english'))\n",
    "#     filtered_sen=[]\n",
    "\n",
    "#     for i in tokenwords:\n",
    "#         if i not in stop_words:\n",
    "#             filtered_sen.append(i)\n",
    "#     fdist=FreqDist(filtered_sen)\n",
    "#     fd=pd.DataFrame(fdist.most_common(20),\n",
    "#                     columns=[\"Word\",\"Frequency\"]).drop([0]).reindex()\n",
    "    \n",
    "    \n",
    "#     fig.add_trace(go.Bar(x=fd[\"Word\"], y=fd[\"Frequency\"], name=\"Freq Dist\"), row=2, col=2)\n",
    "#     fig.update_traces(marker_color='rgb(17,159,249)', marker_line_color='rgb(0,0,0)', \\\n",
    "#             marker_line_width=0.5, opacity=0.7, row=2, col=2)\n",
    "    \n",
    "\n",
    "#     #EMOTIONS \n",
    "#     emotion_counts = df['emotion'].value_counts().reset_index()\n",
    "#     emotion_counts.columns = ['Emotion', 'Count']\n",
    "\n",
    "#     fig.add_trace(go.Bar(x=emotion_counts['Emotion'], y=emotion_counts['Count'], name=\"Emotion Distribution\"), row=2, col=3)\n",
    "#     fig.update_traces(marker_color='rgb(155,89,182)', marker_line_color='rgb(0,0,0)', \\\n",
    "#         marker_line_width=0.5, opacity=0.7, row=2, col=3)\n",
    "    \n",
    "#     fig.show()\n",
    "#     time.sleep(60)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
